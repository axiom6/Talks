<!doctype html>
<html lang="en">

<head>
    <title>Getting to Know Scala for Data Science</title>
    <meta charset="utf-8">
    <meta name="description" content="Reactive Principles in Data Science">
    <meta name="author" content="Tom Flaherty">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="../../lib/bower_components/reveal.js/css/reveal.css">
    <link rel="stylesheet" href="../../lib/bower_components/reveal.js/lib/css/zenburn.css">
    <link rel="stylesheet" href="../../lib/bower_components/reveal.js/css/theme/night.css" data-id="theme">
    <link rel="stylesheet" href="../../lib/css/talk.css">

    <script src="../../lib/bower_components/jquery/dist/jquery.js"></script>
    <script src="../../lib/bower_components/reveal.js/lib/js/head.min.js"></script>
    <script src="../../lib/bower_components/reveal.js/js/reveal.js"></script>
    <script src="../../lib/js/RevealInit.js"></script>
    <!--script src="ASCIIMathML.js"></script>
    <script>mathcolor="yellow"</script-->

</head>

<body>

<div class="reveal">

<div class="slides"  style="color:wheat;">

<section data-id="ScalaDBTitle" class="Title">
  <h1 style="font-size:2.5em;">Getting to Know Scala</h1>
  <h1 style="font-size:2.5em;">for Data Science</h1>
  <a  style="font-size:2.0em;" href="http://twitter.com/TheTomFlaherty">@TheTomFlaherty</a>
</section>

<section data-id="Bio" class="Abstract">
  <h2 style="text-align:left;">Bio:</h2>
  <p>I have been a Chief Architect for 20 years, where he first become enamored by Scala in 2006.
    Over the years I have written a symbolic math application in Scala at Glaxo in 2008 for molecular dynamics
    and in 2010 I formed the Front Range Polyglot Panel and participated as its Scala expert.</p>
  <!--h3 style="text-align:left;">The Real Bio:</h3>
  <p>In the past I enjoyed living in the twilight zone between Data Science and programming where no one bothered me,
    but recently I have realized that Data Science is engaging warp drive and I want to be Captain Kirk.</p-->
</section>

<section data-id="ScalaDBAbstract1" class="Abstract">
  <h2>Abstract</h2>
  <ul>
    <li class="FontSize36px">Scala has gained a lot of traction recently,</li>
    <li class="FontSize36px">Especially in Data Science with:
    <ul>
      <li>Spark</li>
      <li>Cassandra with Spark Connector</li>
      <li>Kafka</li>
    </ul>
  </ul>
</section>

<section data-id="Success Factor" class="Abstract" >
  <h3>So what are Scala's success factors for Data Science?</h3>
  <ul>
    <li>A Strong Affinity to Data</li>
    <li>Functional Programmming with Streaming
      <ul>
        <li>That is Capable of Mirroring Math Syntax</li>
        <li>But only if programmers strive for it</li>
     </ul>
    <li>Awesome Concurrency under the Covers</li>
    <li>The Spark Ecosystem</li>
    <li>A vibrant Open Source comminity around Typesafe and Spark</li>
  </ul>
</section>


<section data-id="Outline">
  <h4>Outline</h4>
  <div style="position:relative;   left:0; top:0; width:100%; height:700px; font-size:22px;">
    <div style="position:absolute; left:0; top:0; width: 40%; height:100%; ">
      <ul>
        <li>Introduction to Scala
          <ul>
            <li>About</li>
            <li>Class  Declarations</li>
            <li>Functions</li>
            <li>Processing Collections</li>
            <li>Methods on Collections</li>
            <li>For Comprehensions</li>
          </ul>
        </li>
        <li>What Data Likes:
          <ul>
            <li>To Be a First Class Citizen</li>
            <li>To Assert Its Identity</li>
            <li>To Remain Intact</li>
            <li>Pattern Matching
              <ul>
                <li>Revealing Data</li>
                <li>Sharing Contents</li>
                <li>Derivative</li>
              </ul>
          </ul>
        </li>
      </ul>
    </div>
    <div style="position:absolute; left:40%; top:0; width:60%;  height:100%; ">
      <ul>
        <li>What do Data Scientist Like
          <ul>
            <li>A Universal Data Representation</li>
            <li>To Simulate Things All at Once</li>
            <li>Data Driven Results</li>
            <li>To Orchestrate Processing</li>
          </ul>
        </li>
        <li>Spark
          <ul>
            <li>Architecure</li>
            <li>RDD Resilient Distributed Data</li>
            <li>RDD Workflow</li>
            <li>Processing Steps</li>
          </ul>
        <li>Orchestrations
          <ul>
            <li>Word Count</li>
            <li>Machine Learning</li>
            <li>Kafka Spark Cassandra</li>
            <li>Grand Finale</li>
          </ul>
        </li>
        <li>References</li>
      </ul>
    </div>
  </div>
</section>

<section data-id="">
  <h1>Introduction</h1>
</section>

<section data-id="">
  <h2>About Scala</h2>
  <ul>
    <li>State of the Art Class Hierarchy + Functional Programming</li>
    <li>Fully Leverages the JVM
      <ul>
        <li>Concurrency from Doug Lea</li>
        <li>JIT (Just IN Time) inlines functional constructs</li>
        <li>Comparable in speed to Java &plusmn;3%</li>
      </ul>
    </li>
    <li>Interoperates with Java
      <ul>
        <li>Can use any Java class (inherit from, etc.)</li>
        <li>Can be called from Java</li>
      </ul>
    </li>
    <li> Statically Typed
      <ul>
        <li>Type inference</li>
      </ul>
    </li>
  </ul>
</section>


<section data-id="">
  <h2>Class and object Declarations</h2>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:44em; border:1px solid white;">
  // [T] is a parameterized type for typing the contents with a class
  // You can parameterize a class with many types [T,U,V]
  // You can embed parameterized types [Key,List[T]]
  trait          Trait[T]{...}
  abstract class Abs[T](       i:Int ) extends Trait[T]{...}
  class          Concrete[T](  i:Int ) extends Abs[T]( i:Int) {...}
  case class     Case[T](      i:Int )
  class          Composite[T]( i:Int ) extends Abs[T]( i:Int)
    with Trait1[T] with Trait2[T] {...}
  </code></pre>
</section>

<section data-id="">
  <h2>Functions</h2>
  <pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
    ( x:Int ) => x + 2 // full version
    x         => x + 2 // type inferred
    _ + 2              // placeholder syntax
    def addTwo( x:Int ) : Int = x + 2 // Regular Function
  </code></pre>
</section>


<section data-id="">
  <h2>Processing a List Collection</h2>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
val list = List(1, 2, 3)        // Scala infers an immutable List[Int]
list.foreach( x => println(x) ) // prints 1, 2, 3
list.foreach( println )         // same
list.map( x => x + 2 )          // returns a new List(3, 4, 5)
list.map( _ + 2 )               // same
list.filter( x => x % 2 == 1)   // returns a new List(1, 3)
list.filter( _ % 2 == 1 )       // same
list.reduce( (x,y) => x + y )   // => 6
list.reduce( _ + _ )            // Placeholder syntax
 // Be expressive self documenting - Use placeholder syntax judiciously
</code></pre>
</section>

<section data-id="">
  <h3>Functional Methods on Seq[T] Collections</h3>
  <table>
    <tr><th>Method on Seq[T]</th><th>Description</th></tr>
    <tr><td><pre class="scala">map(     f:T => U       ) : Seq[U]</pre></td><td>Each element is result of f</td></tr>
    <tr><td><pre class="scala">flatMap( f:T => Seq[U]  ) : Seq[U]</pre></td><td>f returns a seq for each element that are flatten into result</td></tr>
    <tr><td><pre class="scala">filter(  f:T => Boolean ) : Seq[T]</pre></td><td>Keep only elements where f is true</td></tr>
    <tr><td><pre class="scala">exists(  f:T => Boolean ) : Boolean</pre></td><td>True if one element passes f</td></tr>
    <tr><td><pre class="scala">forall(  f:T => Boolean ) : Boolean</pre></td><td>True if all elements pass  f</td></tr>
    <tr><td><pre class="scala">groupBy( f:T => Key     ) : Map[Key,Seq[T]]</pre></td><td>Group elements into a Key Seq Map</td></tr>
    <tr><td><pre class="scala">reduce(  f:(T,T) => T   ) : T</pre></td><td>Summarize elements using an f with two arg</td></tr>
    <tr><td><pre class="scala">....</pre></td><td>... many more methods</td></tr>
  </table>
</section>

<section data-id="">
  <h2>For Comprehensions</h2>
  <pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
  </code></pre>
</section>

<section data-id="ScalaDBAbstract2" class="Abstract">
  <h3>Let's Ask Data What It Likes:</h3>
  <table>
    <tr><th>Data Likes</th><th>Scala Feature</th></tr>
    <tr><td>Being a First Class Citizen</td><td>Primitives As Classes</td></tr>
    <tr><td>To Assert its Identity</td><td>Strong Typing</td></tr>
    <tr><td>To Stay Intact</td><td>Immutability</td></tr>
    <tr><td>To Reveal Its Contents</td><td>Pattern Matching</td></tr>
    <tr><td>To Share its Contents</td><td>Case Classes</td></tr>
    <tr><td>Resilient Packaging</td><td>Monads</td></tr>
  </table>
</section>


<section data-id="">
  <h3>Data is First Class Citizen</h3>
  <h3>with Scala's Class Hierarchy</h3>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:44em; border:1px solid white;">
Any
  AnyVal           // Scala's base class for Java primitives and Unit
    Double Float Long Int Short Char Byte Boolean Unit
  scala.Array      // compiles to Java arrays [] most of the time
  AnyRef           // compiles to java.lang.Object
    String         // compiles to java.lang.String
    (all other Java Classes ...)
    scala.ScalaObject
      (all other Scala Classes ...)
      scala.Seq    // base Class for all ordered collections

      scala.List   // Immutable list for pattern matching
      scala.Option // Yields to Some(value) or None
    scala.Null     // is a subtype for all AnyRef classes
                   // For Java compatibility. Better to use Option
  scala.Nothing    // is a subtype of all Any classes. A true empty value

  5.toString() is valid because 5 is an object
</code></pre>
</section>

<section data-id="">
  <h2>Asserting Identity with Types</h2>
  <pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
  </code></pre>
</section>

<section data-id="">
  <h2>Staying Intact - Immutability</h2>
  <pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
  </code></pre>
</section>



<section data-id="">
  <h2>Revealing Contents</h2>
</section>

  <section data-id="">
    <h2>Sharing Contents</h2>
    <h3>OO Encapsulation Got it All Wrong</h3>
  </section>

  <section data-id="">
  <h1>Pattern Matching</h1>
  <h2>with Case Classes</h2>
</section>


<section data-id="">
  <h3>Message Interogation using</h3>
  <h3>Pattern Matching with Scala Actors</h3>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
</code></pre>
</section>

<section data-id="ScalaDBAbstract2" class="Abstract">
  <h3>What Do Data Scientists Like?</h3>
  <table class="FontSize28px">
    <tr><th>Scientists Like</th><th>Spark Feature</th></tr>
    <tr><td>A Universal Data Representation</td><td>RDD Resilent Distributed Data</td></tr>
    <tr><td>To Simulate Things All at Once</td><td>Concurrency</td></tr>
    <tr><td>Data Driven Results</td><td>Pattern Matching</td></tr>
    <tr><td>To Orchestrate Processing</td><td>Streams</td></tr>
  </table>
</section>

<section data-id="">
  <div   style="position:absolute; left: 0;   top: 0;  width:960px; height:700px; color:white;">
    <div style="position:absolute; left: 0;   top:12%; width:100%;  height:10%;    background-color:blue;  border-radius:16px; font-size:36pt;">Your Code</div>
    <div style="position:absolute; left: 0;   top:24%; width:100%;  height:10%;    background-color:blue;  border-radius:16px; font-size:36pt;">Spark Streaming of RDDs</div>
    <div style="position:absolute; left: 0;   top:36%; width:100%;  height:10%;    background-color:blue;  border-radius:16px;;"><img src="../img/logo/AkkaLogo.png" height="72" style=" border:none;"></div>
 <!--div style="position:absolute; left:13%;  top:46%; width:  4%;  height:28%;    background-color:blue;  z-index:2;"></div>
    <div style="position:absolute; left:48%;  top:46%; width:  4%;  height:28%;    background-color:blue;  z-index:2;"></div>
    <div style="position:absolute; left:83%;  top:46%; width:  4%;  height:28%;    background-color:blue;  z-index:2;"></div-->
    <div style="position:absolute; left: 0;   top:49%; width: 30%;  height:25%;    background-color:steelblue;"></div>
    <div style="position:absolute; left: 0;   top:74%; width: 30%;  height:25%;    background-color:steelblue;"><img src="../img/logo/KafkaLogo.png" width="288" height="175"  style=" border:none;"></div>
    <div style="position:absolute; left:35%;  top:49%; width: 30%;  height:25%;    background-color:#FFFF99;"></div>
    <div style="position:absolute; left:35%;  top:74%; width: 30%;  height:25%;    background-color:goldenrod;"><img src="../img/logo/MLlibLogo2.png" width="288" height="175"></div>
    <div style="position:absolute; left:70%;  top:49%; width: 30%;  height:25%;    background-color:#FF9999;"></div>
    <div style="position:absolute; left:70%;  top:74%; width: 30%;  height:25%;    background-color:sienna;"><img src="../img/logo/CassandraLogo2.png" width="288" height="175"></div>
  </div>
</section>



<section data-id="">
  <h2>RDD Resilient Distributed Data</h2>
</section>

  <section data-id="">
    <h2>RDD Workflow</h2>
    <img src="../img/spark/RDDWorkflow.png">
  </section>

<section data-id="">
  <h2>Transformations</h2>
  <ul>
    <li>Create a new dataset from an existing one</li>
    <li>All transformations in Spark are lazy
      <ul>
        <li>They do not compute their results right away</li>
        <li>Instead they remember the applied transformations</li>
      </ul>
    </li>
    <li>In Order To
      <ul>
        <li>optimize the required calculations</li>
        <li>recover from lost data partitions</li>
      </ul>
    </li>
  </ul>
</section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Transformation Methods</h3>
  <pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
      map[U](     f:(T) => U       ) : RDD[U]
      flatMap[U]( f:(T) => Seq[U]  ) : RDD[U]
      filter(     f:(T) => Boolean ) : RDD[T]

      keyBy[K](   f:(T) => K ) : RDD[(K,T)]
      groupBy[K]( f:(T) => K ) : RDD[(K,Iterable[T])]

      glom(                    ) : RDD[T]
      distinct(                ) : RDD[T]
      intersection( rdd:RDD[T] ) : RDD[T]
      subtract(     rdd:RDD[T] ) : RDD[T]
      union(        rdd:RDD[T] ) : RDD[T]
      cartesian[U]( rdd:RDD[U] ) : RDD[(T,U)]
      zip[U](       rdd:RDD[U] ) : RDD[(T,U))

      sample( r:Boolean, f:Double, s:Long ): RDD[T]
      pipe(command: String): RDD[String]
      coalesce( numPartitions: Int, shuffle: Boolean ) : RDD[T]
      mapPartitions
    reduceByKey
    aggregateByKey
    sortByKey
    join

    repartition
    coalesce
    cogroup
  </code></pre>
  </section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Transformation Methods</h3>
    <table class="FontSize28px">
      <tr><th></th><th></th></tr>
      <tr><td> sample(withReplacement: Boolean, fraction: Double, seed: Long = Utils.random.nextLong): RDD[T] </td><td>sample a fraction fraction of the data, with or withoutreplacement, using a given random number generatorseed</td></tr>
      <tr><td>union(otherDataset)</td><td>return a new dataset that contains the union of the elements in the source dataset and the argument</td></tr>
      <tr><td>distinct([numTasks]))</td><td>return a new dataset that contains the distinct elements of the source dataset</td></tr>
      <tr><td>
    </table>
  </section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Transformation Methods</h3>
  <table >
    <tbody><tr><th style="width:25%">Transformation</th><th>Meaning</th></tr>
    <tr>
      <td> <b>map</b>(<i>func</i>) </td>
      <td> Return a new distributed dataset formed by passing each element of the source through a function <i>func</i>. </td>
    </tr>
    <tr>
      <td> <b>filter</b>(<i>func</i>) </td>
      <td> Return a new dataset formed by selecting those elements of the source on which <i>func</i> returns true. </td>
    </tr>
    <tr>
      <td> <b>flatMap</b>(<i>func</i>) </td>
      <td> Similar to map, but each input item can be mapped to 0 or more output items (so <i>func</i> should return a Seq rather than a single item). </td>
    </tr>
    <tr>
      <td> <b>mapPartitions</b>(<i>func</i>) <a name="MapPartLink"></a> </td>
      <td> Similar to map, but runs separately on each partition (block) of the RDD, so <i>func</i> must be of type
        Iterator&lt;T&gt; =&gt; Iterator&lt;U&gt; when running on an RDD of type T. </td>
    </tr>
    <tr>
      <td> <b>mapPartitionsWithIndex</b>(<i>func</i>) </td>
      <td> Similar to mapPartitions, but also provides <i>func</i> with an integer value representing the index of
        the partition, so <i>func</i> must be of type (Int, Iterator&lt;T&gt;) =&gt; Iterator&lt;U&gt; when running on an RDD of type T.
      </td>
    </tr>
    <tr>
      <td> <b>sample</b>(<i>withReplacement</i>, <i>fraction</i>, <i>seed</i>) </td>
      <td> Sample a fraction <i>fraction</i> of the data, with or without replacement, using a given random number generator seed. </td>
    </tr>
    <tr>
      <td> <b>union</b>(<i>otherDataset</i>) </td>
      <td> Return a new dataset that contains the union of the elements in the source dataset and the argument. </td>
    </tr>
    <tr>
      <td> <b>intersection</b>(<i>otherDataset</i>) </td>
      <td> Return a new RDD that contains the intersection of elements in the source dataset and the argument. </td>
    </tr>
    <tr>
      <td> <b>distinct</b>([<i>numTasks</i>])) </td>
      <td> Return a new dataset that contains the distinct elements of the source dataset.</td>
    </tr>
    <tr>
      <td> <b>groupByKey</b>([<i>numTasks</i>]) <a name="GroupByLink"></a> </td>
      <td> When called on a dataset of (K, V) pairs, returns a dataset of (K, Iterable&lt;V&gt;) pairs. <br>
        <b>Note:</b> If you are grouping in order to perform an aggregation (such as a sum or
        average) over each key, using <code>reduceByKey</code> or <code>aggregateByKey</code> will yield much better
        performance.
        <br>
        <b>Note:</b> By default, the level of parallelism in the output depends on the number of partitions of the parent RDD.
        You can pass an optional <code>numTasks</code> argument to set a different number of tasks.
      </td>
    </tr>
    <tr>
      <td> <b>reduceByKey</b>(<i>func</i>, [<i>numTasks</i>]) <a name="ReduceByLink"></a> </td>
      <td> When called on a dataset of (K, V) pairs, returns a dataset of (K, V) pairs where the values for each key are aggregated using the given reduce function <i>func</i>, which must be of type (V,V) =&gt; V. Like in <code>groupByKey</code>, the number of reduce tasks is configurable through an optional second argument. </td>
    </tr>
    <tr>
      <td> <b>aggregateByKey</b>(<i>zeroValue</i>)(<i>seqOp</i>, <i>combOp</i>, [<i>numTasks</i>]) <a name="AggregateByLink"></a> </td>
      <td> When called on a dataset of (K, V) pairs, returns a dataset of (K, U) pairs where the values for each key are aggregated using the given combine functions and a neutral "zero" value. Allows an aggregated value type that is different than the input value type, while avoiding unnecessary allocations. Like in <code>groupByKey</code>, the number of reduce tasks is configurable through an optional second argument. </td>
    </tr>
    <tr>
      <td> <b>sortByKey</b>([<i>ascending</i>], [<i>numTasks</i>]) <a name="SortByLink"></a> </td>
      <td> When called on a dataset of (K, V) pairs where K implements Ordered, returns a dataset of (K, V) pairs sorted by keys in ascending or descending order, as specified in the boolean <code>ascending</code> argument.</td>
    </tr>
    <tr>
      <td> <b>join</b>(<i>otherDataset</i>, [<i>numTasks</i>]) <a name="JoinLink"></a> </td>
      <td> When called on datasets of type (K, V) and (K, W), returns a dataset of (K, (V, W)) pairs with all pairs of elements for each key.
        Outer joins are supported through <code>leftOuterJoin</code>, <code>rightOuterJoin</code>, and <code>fullOuterJoin</code>.
      </td>
    </tr>
    </tbody>



  </table>
  </section>
  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Transformation Methods</h3>
    <table  class="FontSize18px">
      <tbody><tr><th style="width:25%">Transformation</th><th>Meaning</th></tr>
      <tr>
    <tr>
      <td> <b>cogroup</b>(<i>otherDataset</i>, [<i>numTasks</i>]) <a name="CogroupLink"></a> </td>
      <td> When called on datasets of type (K, V) and (K, W), returns a dataset of (K, (Iterable&lt;V&gt;, Iterable&lt;W&gt;)) tuples. This operation is also called <code>groupWith</code>. </td>
    </tr>
    <tr>
      <td> <b>cartesian</b>(<i>otherDataset</i>) </td>
      <td> When called on datasets of types T and U, returns a dataset of (T, U) pairs (all pairs of elements). </td>
    </tr>
    <tr>
      <td> <b>pipe</b>(<i>command</i>, <i>[envVars]</i>) </td>
      <td> Pipe each partition of the RDD through a shell command, e.g. a Perl or bash script. RDD elements are written to the
        process's stdin and lines output to its stdout are returned as an RDD of strings. </td>
    </tr>
    <tr>
      <td> <b>coalesce</b>(<i>numPartitions</i>) <a name="CoalesceLink"></a> </td>
      <td> Decrease the number of partitions in the RDD to numPartitions. Useful for running operations more efficiently
        after filtering down a large dataset. </td>
    </tr>
    <tr>
      <td> <b>repartition</b>(<i>numPartitions</i>) </td>
      <td> Reshuffle the data in the RDD randomly to create either more or fewer partitions and balance it across them.
        This always shuffles all data over the network. <a name="RepartitionLink"></a></td>
    </tr>
    <tr>
      <td> <b>repartitionAndSortWithinPartitions</b>(<i>partitioner</i>) <a name="Repartition2Link"></a></td>
      <td> Repartition the RDD according to the given partitioner and, within each resulting partition,
        sort records by their keys. This is more efficient than calling <code>repartition</code> and then sorting within
        each partition because it can push the sorting down into the shuffle machinery. </td>
    </tr>
    </tbody>
  </table>
  </section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Transformation Methods</h3>
  <tbody><tr><th>Action</th><th>Meaning</th></tr>
  <tr>
    <td> <b>reduce</b>(<i>func</i>) </td>
    <td> Aggregate the elements of the dataset using a function <i>func</i> (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel. </td>
  </tr>
  <tr>
    <td> <b>collect</b>() </td>
    <td> Return all the elements of the dataset as an array at the driver program. This is usually useful after a filter or other operation that returns a sufficiently small subset of the data. </td>
  </tr>
  <tr>
    <td> <b>count</b>() </td>
    <td> Return the number of elements in the dataset. </td>
  </tr>
  <tr>
    <td> <b>first</b>() </td>
    <td> Return the first element of the dataset (similar to take(1)). </td>
  </tr>
  <tr>
    <td> <b>take</b>(<i>n</i>) </td>
    <td> Return an array with the first <i>n</i> elements of the dataset. </td>
  </tr>
  <tr>
    <td> <b>takeSample</b>(<i>withReplacement</i>, <i>num</i>, [<i>seed</i>]) </td>
    <td> Return an array with a random sample of <i>num</i> elements of the dataset, with or without replacement, optionally pre-specifying a random number generator seed.</td>
  </tr>
  <tr>
    <td> <b>takeOrdered</b>(<i>n</i>, <i>[ordering]</i>) </td>
    <td> Return the first <i>n</i> elements of the RDD using either their natural order or a custom comparator. </td>
  </tr>
  <tr>
    <td> <b>saveAsTextFile</b>(<i>path</i>) </td>
    <td> Write the elements of the dataset as a text file (or set of text files) in a given directory in the local filesystem, HDFS or any other Hadoop-supported file system. Spark will call toString on each element to convert it to a line of text in the file. </td>
  </tr>
  <tr>
    <td> <b>saveAsSequenceFile</b>(<i>path</i>) <br> (Java and Scala) </td>
    <td> Write the elements of the dataset as a Hadoop SequenceFile in a given path in the local filesystem, HDFS or any other Hadoop-supported file system. This is available on RDDs of key-value pairs that implement Hadoop's Writable interface. In Scala, it is also
      available on types that are implicitly convertible to Writable (Spark includes conversions for basic types like Int, Double, String, etc). </td>
  </tr>
  <tr>
    <td> <b>saveAsObjectFile</b>(<i>path</i>) <br> (Java and Scala) </td>
    <td> Write the elements of the dataset in a simple format using Java serialization, which can then be loaded using
      <code>SparkContext.objectFile()</code>. </td>
  </tr>
  <tr>
    <td> <b>countByKey</b>() <a name="CountByLink"></a> </td>
    <td> Only available on RDDs of type (K, V). Returns a hashmap of (K, Int) pairs with the count of each key. </td>
  </tr>
  <tr>
    <td> <b>foreach</b>(<i>func</i>) </td>
    <td> Run a function <i>func</i> on each element of the dataset. This is usually done for side effects such as updating an <a href="#AccumLink">Accumulator</a> or interacting with external storage systems.
      <br><b>Note</b>: modifying variables other than Accumulators outside of the <code>foreach()</code> may result in undefined behavior. See <a href="#ClosuresLink">Understanding closures </a> for more details.</td>
  </tr>
  </tbody>
  </table>
  </section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Transformation Methods</h3>
    <table class="FontSize28px">
      <tr><th></th><th></th><th></th></tr>
      <tr><td> cartesian[U](other: RDD[U]) : RDD[(T,U)]</td><td> collect[U](f: PartialFunction[T, U]): RDD[U] 
      <tr><td> distinct(): RDD[T] </td><td> filter(f: (T) ⇒ Boolean): RDD[T] </td> flatMap[U](f: (T) ⇒ TraversableOnce[U])(implicit arg0: ClassTag[U]): RDD[U] <td></td></tr>
      <tr><td> glom(): RDD[Array[T]] </td><td> groupBy[K](f: (T) ⇒ K)(implicit kt: ClassTag[K]): RDD[(K, Iterable[T])] </td><td> intersection(other: RDD[T]): RDD[T] </td></tr>
      <tr><td> keyBy[K](f: (T) ⇒ K): RDD[(K, T)] </td><td> map[U](f: (T) ⇒ U)(implicit arg0: ClassTag[U]): RDD[U] 
      <tr><td> union(other: RDD[T]): RDD[T] </td><td> zip[U](other: RDD[U])(implicit arg0: ClassTag[U]): RDD[(T, U)] 
      <tr><td></td><td>
    </table>
  </section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>Action Methods</h3>
    <table class="FontSize28px">
      <tr><th></th><th></th><th></th></tr>
      <tr><td> collect(): Array[T] </td><td> count(): Long 
      <tr><td> fold(zeroValue: T)(op: (T, T) ⇒ T): T </td><td> reduce(f: (T, T) ⇒ T): T </td><td> take(num: Int): Array[T] </td></tr>
      <tr><td> max()(implicit ord: Ordering[T]): T </td><td> min()(implicit ord: Ordering[T]): T </td><td> subtract(other: RDD[T]): RDD[T] </td></tr>
      <tr><td> takeOrdered(num: Int)(implicit ord: Ordering[T]): Array[T] </td><td> takeSample(withReplacement: Boolean, num: Int, seed: Long = Utils.random.nextLong): Array[T] </td><td> top(num: Int)(implicit ord: Ordering[T]): Array[T] </td></tr>
      <tr><td></td><td>
      <tr><td></td><td>
      <tr><td></td><td>
    </table>
  </section>

  <section data-id="ScalaDBAbstract2" class="Abstract">
    <h3>SAve Methods</h3>
    <table class="FontSize28px">
      <tr><th></th><th></th><th></th></tr>
      <tr><td> saveAsObjectFile(path: String): Unit </td><td>f saveAsTextFile(path: String): Unit 
      <tr><td></td><td>
      <tr><td></td><td>
      <tr><td></td><td>
    </table>
  </section>


  <section data-id="">
    <h2>Processing Steps</h2>
  </section>

  <section data-id="">
    <h3>Data Driven Results</h3>
    <h3>Pattern Matching</h3>
  </section>








<section data-id="">
  <h1>Orchestration</h1>
</section>

<section data-id="">
  <h2>Word Count</h2>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
  val f = sc.textFile("README.md")!
  val wc = f.flatMap(l => l.split(" ")).map(word => (word, 1)).reduceByKey(_ + _)!
  wc.saveAsTextFile("wc_out")
</code></pre>
</section>


<section data-id="">
  <h2>Machine Learning</h2>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
</code></pre>
</section>

<section data-id="">
  <h2>Kafka Spark Cassandra</h2>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
</code></pre>
</section>

<section data-id="">
  <h2>Grand Finale</h2>
<pre class="scala"><code style="font-size:1em; min-height:24em;  min-width:40em; border:1px solid white;">
</code></pre>
</section>


<section data-id="ScalaDBReferences">
  <h2>References</h2>
  <ul style="margin-left:0.6em; font-size:26px;">
      <li><div class="width340">Big Data Driving Business</div><a href="http://www.ted.com/talks/philip_evans_how_data_will_transform_business">http://bit.ly/194auY9</a></li>
      <li><div class="width340">REST API Tutorial</div><a href="http://www.restapitutorial.com/resources.html">http://www.restapitutorial.com/resources.html</a></li>
      <li><div class="width340">CAP Theorem</div><a href="http://en.wikipedia.org/wiki/CAP_theorem">http://en.wikipedia.org/wiki/CAP_theorem</a></li>
      <li><div class="width340">Grid Gain</div><a href="http://www.gridgain.com/">http://www.gridgain.com/</a></li>
      <li><div class="width340">Apache Spark</div><a href="https://spark.apache.org/">https://spark.apache.org/</a></li>
      <li><div class="width340">The Reactive Manifesto</div><a href="http://www.reactivemanifesto.org/">www.reactivemanifesto.org/</a></li>
      <li><div class="width340">These slides in PDF</div><a href="https://speakerdeck.com/axiom6">https://speakerdeck.com/axiom6</a></li>
  </ul>
</section>

<section data-id="ScalaDBTheEnd">
    <h1>THE END</h1>
</section>

</div>
</div>

</body>
</html>
